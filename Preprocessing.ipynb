{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Preprocessing.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMn4NZpsPxjRvhQE+akjTWa"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"zBitKlsp4rkf","colab":{"base_uri":"https://localhost:8080/","height":898},"executionInfo":{"status":"ok","timestamp":1622477939497,"user_tz":-120,"elapsed":77454,"user":{"displayName":"Giulio Cerruto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhW2Eu1p6y3oJGuXwKvRHcooa_OFElVoGD8oA7WiA=s64","userId":"15268458970073686622"}},"outputId":"2582744f-5168-4359-9184-b55597f89d33"},"source":["import os\n","import logging\n","\n","from PIL import Image\n","from tqdm import tqdm\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","\n","import json\n","\n","import nltk\n","nltk.download('wordnet')\n","nltk.download('punkt')\n","from nltk.corpus import wordnet\n","from nltk.stem import WordNetLemmatizer\n","from nltk.tokenize import word_tokenize"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting tensorflow-gpu\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/a2/5ccf0a418eb22e0a2ae9edc1e7f5456d0a4b8b49524572897564b4030a9b/tensorflow_gpu-2.5.0-cp37-cp37m-manylinux2010_x86_64.whl (454.3MB)\n","\u001b[K     |████████████████████████████████| 454.3MB 38kB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.15.0)\n","Requirement already satisfied, skipping upgrade: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.36.2)\n","Requirement already satisfied, skipping upgrade: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.4.0)\n","Requirement already satisfied, skipping upgrade: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.12.1)\n","Requirement already satisfied, skipping upgrade: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.12)\n","Requirement already satisfied, skipping upgrade: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.3.0)\n","Requirement already satisfied, skipping upgrade: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.6.3)\n","Requirement already satisfied, skipping upgrade: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.12.0)\n","Requirement already satisfied, skipping upgrade: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.2)\n","Requirement already satisfied, skipping upgrade: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.0)\n","Requirement already satisfied, skipping upgrade: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.19.5)\n","Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.12.4)\n","Requirement already satisfied, skipping upgrade: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.1.0)\n","Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.5.0)\n","Requirement already satisfied, skipping upgrade: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.5.0)\n","Requirement already satisfied, skipping upgrade: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.7.4.3)\n","Requirement already satisfied, skipping upgrade: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.34.1)\n","Requirement already satisfied, skipping upgrade: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.2.0)\n","Requirement already satisfied, skipping upgrade: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.5.0.dev2021032900)\n","Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow-gpu) (56.1.0)\n","Requirement already satisfied, skipping upgrade: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow-gpu) (1.5.2)\n","Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu) (1.8.0)\n","Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu) (0.4.4)\n","Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu) (1.30.0)\n","Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu) (2.23.0)\n","Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu) (1.0.1)\n","Requirement already satisfied, skipping upgrade: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu) (0.6.1)\n","Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu) (3.3.4)\n","Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow-gpu) (1.3.0)\n","Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow-gpu) (4.2.2)\n","Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow-gpu) (0.2.8)\n","Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow-gpu) (4.7.2)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-gpu) (2.10)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-gpu) (1.24.3)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-gpu) (3.0.4)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-gpu) (2020.12.5)\n","Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow-gpu) (4.0.1)\n","Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow-gpu) (3.1.0)\n","Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow-gpu) (0.4.8)\n","Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow-gpu) (3.4.1)\n","Installing collected packages: tensorflow-gpu\n","Successfully installed tensorflow-gpu-2.5.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["tensorflow"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"Y_vUixHg448h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622477947030,"user_tz":-120,"elapsed":7556,"user":{"displayName":"Giulio Cerruto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhW2Eu1p6y3oJGuXwKvRHcooa_OFElVoGD8oA7WiA=s64","userId":"15268458970073686622"}},"outputId":"6834572a-fbc9-493e-f59d-7daba019634b"},"source":["# we get the data cloning our github repository\n","\n","if not os.path.isdir('./COCO'):\n","  !git clone https://github.com/MarcoSaponara/MLAI_LINKS_project.git\n","  !mv 'Conditional_Text_Generation_Project' 'CTRL'\n","\n","with open(\"CTRL/annotations_train_val_2014/captions_train2014.json\",\"r\") as f:\n","  train_dataset = json.load(f)\n","\n","with open(\"CTRL/annotations_train_val_2014/captions_val2014.json\",\"r\") as f:\n","  val_dataset = json.load(f)\n","\n","with open(\"CTRL/annotations_test_2014/image_info_test2014.json\",\"r\") as f:\n","  test_dataset = json.load(f)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'MLAI_LINKS_project'...\n","remote: Enumerating objects: 39, done.\u001b[K\n","remote: Counting objects: 100% (39/39), done.\u001b[K\n","remote: Compressing objects: 100% (37/37), done.\u001b[K\n","remote: Total 39 (delta 14), reused 3 (delta 1), pack-reused 0\u001b[K\n","Unpacking objects: 100% (39/39), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ILNtsXVsqbWm"},"source":["ds = CocoDataset(path='COCO/annotations_train_val_2014/captions_train2014.json', text_field=data.Field())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xshOYoNm5m3v","executionInfo":{"status":"ok","timestamp":1619455793206,"user_tz":-120,"elapsed":516,"user":{"displayName":"Giulio Cerruto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhW2Eu1p6y3oJGuXwKvRHcooa_OFElVoGD8oA7WiA=s64","userId":"15268458970073686622"}},"outputId":"c2f63003-3014-42bc-ee15-d328b9363ae6"},"source":["# dataset description\n","\n","print(train_dataset.keys())\n","print(\" info is a dict that gives info about the dataset \\n licenses is a list of licenses related to the source of the images \")\n","print(\"\\n\")\n","print(\"images is a list of dictionaries , each dict is a photo and contains basic info like the url, dimensions and id\")\n","print(train_dataset['images'][0].keys(),len(train_dataset['images']), \" elements\")\n","print(\"\\n\")\n","print(\"annotations is a list of dictionaries, each dict is a caption\")\n","print(train_dataset['annotations'][0].keys(),len(train_dataset['annotations']), \" elements\")\n","print(\"there are much more captions than images so each image has more than one caption\")\n","print(\"\\n\")\n","print(\"test set is the same but instead of the annotations it provides us the categories of the images it contains\")\n","print(test_dataset.keys(), len(test_dataset['images']))\n","print(\"categories is a list of dictionaries, each dict is one of the categories\")\n","print(test_dataset['categories'][0].keys())\n","print(\"supercategory is a general category while name is a more specific one\")\n","print(\"example: \",test_dataset['categories'][1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["dict_keys(['info', 'images', 'licenses', 'annotations'])\n"," info is a dict that gives info about the dataset \n"," licenses is a list of licenses related to the source of the images \n","\n","\n","images is a list of dictionaries , each dict is a photo and contains basic info like the url, dimensions and id\n","dict_keys(['license', 'file_name', 'coco_url', 'height', 'width', 'date_captured', 'flickr_url', 'id']) 82783  elements\n","\n","\n","annotations is a list of dictionaries, each dict is a caption\n","dict_keys(['image_id', 'id', 'caption']) 414113  elements\n","there are much more captions than images so each image has more than one caption\n","\n","\n","test set is the same but instead of the annotations it provides us the categories of the images it contains\n","dict_keys(['info', 'images', 'licenses', 'categories']) 40775\n","categories is a list of dictionaries, each dict is one of the categories\n","dict_keys(['supercategory', 'id', 'name'])\n","supercategory is a general category while name is a more specific one\n","example:  {'supercategory': 'vehicle', 'id': 2, 'name': 'bicycle'}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ccUvc7o85pmG"},"source":["N_images = len(train_dataset['images'])\n","lista_im = []\n","for i in range(N_images):\n","  lista_im.append(train_dataset['images'][i]['id'])\n","lista_im.sort()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GMu0cQtF6Twe"},"source":["N_capts = len(train_dataset['annotations'])\n","lista_cap = []\n","lista_im_cap = []\n","for i in range(N_capts):\n","  lista_cap.append(train_dataset['annotations'][i]['caption'])\n","  lista_im_cap.append(train_dataset['annotations'][i]['image_id'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":514},"id":"MvsOMBe16WHU","executionInfo":{"elapsed":773,"status":"ok","timestamp":1609967895427,"user":{"displayName":"Giulio Cerruto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhW2Eu1p6y3oJGuXwKvRHcooa_OFElVoGD8oA7WiA=s64","userId":"15268458970073686622"},"user_tz":-60},"outputId":"f41f300f-99ab-4838-afad-8492a53dd1d5"},"source":["immagini = pd.DataFrame(data=lista_im, columns=['image_id']) # DF with images' IDs\n","captions = pd.DataFrame(data=lista_im_cap, columns=['image_id']) # DF with... \n","captions['capt'] = lista_cap #... captions and their corresponding image\n","capt_image = pd.merge(captions,immagini) # DF with all the captions of all the images\n","capt_image_group = capt_image.groupby('image_id') # grouped DF by image id\n","capt_image.head(15)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image_id</th>\n","      <th>capt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>318556</td>\n","      <td>A very clean and well decorated empty bathroom</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>318556</td>\n","      <td>A blue and white bathroom with butterfly theme...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>318556</td>\n","      <td>A bathroom with a border of butterflies and bl...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>318556</td>\n","      <td>An angled view of a beautifully decorated bath...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>318556</td>\n","      <td>A clock that blends in with the wall hangs in ...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>116100</td>\n","      <td>A panoramic view of a kitchen and all of its a...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>116100</td>\n","      <td>A panoramic photo of a kitchen and dining room</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>116100</td>\n","      <td>A wide angle view of the kitchen work area</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>116100</td>\n","      <td>multiple photos of a brown and white kitchen.</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>116100</td>\n","      <td>A kitchen that has a checkered patterned floor...</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>379340</td>\n","      <td>A graffiti-ed stop sign across the street from...</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>379340</td>\n","      <td>A vandalized stop sign and a red beetle on the...</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>379340</td>\n","      <td>A red stop sign with a Bush bumper sticker und...</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>379340</td>\n","      <td>A stop sign that has been vandalized is pictur...</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>379340</td>\n","      <td>A street sign modified to read stop bush.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    image_id                                               capt\n","0     318556     A very clean and well decorated empty bathroom\n","1     318556  A blue and white bathroom with butterfly theme...\n","2     318556  A bathroom with a border of butterflies and bl...\n","3     318556  An angled view of a beautifully decorated bath...\n","4     318556  A clock that blends in with the wall hangs in ...\n","5     116100  A panoramic view of a kitchen and all of its a...\n","6     116100     A panoramic photo of a kitchen and dining room\n","7     116100         A wide angle view of the kitchen work area\n","8     116100     multiple photos of a brown and white kitchen. \n","9     116100  A kitchen that has a checkered patterned floor...\n","10    379340  A graffiti-ed stop sign across the street from...\n","11    379340  A vandalized stop sign and a red beetle on the...\n","12    379340  A red stop sign with a Bush bumper sticker und...\n","13    379340  A stop sign that has been vandalized is pictur...\n","14    379340          A street sign modified to read stop bush."]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"621vWssvluQb","executionInfo":{"status":"ok","timestamp":1619455795853,"user_tz":-120,"elapsed":548,"user":{"displayName":"Giulio Cerruto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhW2Eu1p6y3oJGuXwKvRHcooa_OFElVoGD8oA7WiA=s64","userId":"15268458970073686622"}},"outputId":"a4ae1b40-cb4b-4a51-acac-fd6a09916397"},"source":["names = set()\n","for item in test_dataset['categories']:\n","  names.add(item['name'])\n","print(names)\n","supercategories = set()\n","for item in test_dataset['categories']:\n","  supercategories.add(item['supercategory'])\n","print(supercategories)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'clock', 'sports ball', 'spoon', 'bed', 'teddy bear', 'bus', 'tie', 'cup', 'donut', 'knife', 'apple', 'elephant', 'bird', 'traffic light', 'fire hydrant', 'baseball bat', 'stop sign', 'dog', 'cat', 'motorcycle', 'cow', 'skis', 'bear', 'couch', 'horse', 'person', 'fork', 'boat', 'bench', 'train', 'bowl', 'umbrella', 'broccoli', 'handbag', 'oven', 'tv', 'sink', 'surfboard', 'backpack', 'toothbrush', 'zebra', 'pizza', 'microwave', 'airplane', 'parking meter', 'bottle', 'car', 'book', 'sandwich', 'vase', 'hair drier', 'hot dog', 'skateboard', 'truck', 'potted plant', 'wine glass', 'carrot', 'cell phone', 'remote', 'giraffe', 'mouse', 'sheep', 'suitcase', 'snowboard', 'chair', 'tennis racket', 'cake', 'keyboard', 'laptop', 'refrigerator', 'toilet', 'baseball glove', 'dining table', 'bicycle', 'orange', 'scissors', 'toaster', 'frisbee', 'banana', 'kite'}\n","{'animal', 'sports', 'appliance', 'indoor', 'outdoor', 'accessory', 'kitchen', 'furniture', 'electronic', 'person', 'vehicle', 'food'}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Tf_kFFf-pqpd"},"source":["full_objects_list = pd.read_csv(\"COCO/full_objects_list.txt\", sep=';')\n","full_objects_list = full_objects_list.rename(columns={'ID':'id', 'Object (Paper)':'name', 'Super Category':'supercategory'})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RCDadjjOMMBq"},"source":["def check_caption(cap):\n","  ids = list() # to store the ids of the categories related to the caption\n","\n","  #for cat in test_dataset['categories']:\n","  for i, cat in full_objects_list.iterrows():\n","    if cat['supercategory'] == 'person':\n","      synonyms = list()\n","      synonyms.append('person')\n","      synonyms.append('man')\n","      synonyms.append('woman')\n","      synonyms.append('couple')\n","      synonyms.append('group')\n","      synonyms.append('people')\n","      synonyms.append('girl')\n","      synonyms.append('boy')\n","      \n","      for syn in synonyms:\n","        if syn in cap:\n","          ids.append(cat['id'])\n","          break\n","\n","    else:\n","      if cat['supercategory'] in cap:\n","        ids.append(cat['id'])\n","      \n","  if ids is not None: # look for names in categories\n","    #for cat in test_dataset['categories']:\n","    for i, cat in full_objects_list.iterrows():\n","      if cat['name'] in cap:\n","        ids.append(cat['id'])\n","\n","  return ids\n","\n","def lemmarize(text):\n","  wnl = WordNetLemmatizer()\n","  tokens = [token.lower() for token in word_tokenize(text)]\n","  lemmatized_words = [wnl.lemmatize(token) for token in tokens]\n","  return lemmatized_words"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wTcwlu9ypNO-"},"source":["for annot in train_dataset['annotations']:\n","  annot['lab_ids'] = check_caption(lemmarize(annot['caption']))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V2MKwO2jEIBn","executionInfo":{"elapsed":579,"status":"ok","timestamp":1612404259296,"user":{"displayName":"Giulio Cerruto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhW2Eu1p6y3oJGuXwKvRHcooa_OFElVoGD8oA7WiA=s64","userId":"15268458970073686622"},"user_tz":-60},"outputId":"2e6f4cb3-638d-45bc-b7da-f86f84c12a0c"},"source":["unlabeled = 0\n","for an in train_dataset['annotations']:\n","  if not an['lab_ids']:\n","    unlabeled = unlabeled + 1\n","\n","print('unlabeled captions: ' + str(100*unlabeled/len(train_dataset['annotations']))+'%')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["unlabeled captions: 18.2071077218054%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BtMKL41E2cor"},"source":["catlabs = {new_list: [] for new_list in full_objects_list['id']}\n","\n","for annot in train_dataset['annotations']:\n","  for id in annot['lab_ids']:\n","    catlabs[id].append(annot['id'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r2jnVTTK5us0"},"source":["with open('./train_labels.json', 'w') as fp:\n","    json.dump(catlabs, fp)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qkqfu6FLtOq6"},"source":["### DATASET GENERATION"]},{"cell_type":"code","metadata":{"id":"Ir1Rc5Th8Mbe"},"source":["with open('CTRL/annotations_train_val_2014/train_labels.json','r') as f:\n","  ds = json.load(f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XPjz_aa_pjQj","executionInfo":{"status":"ok","timestamp":1622477962950,"user_tz":-120,"elapsed":352,"user":{"displayName":"Giulio Cerruto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhW2Eu1p6y3oJGuXwKvRHcooa_OFElVoGD8oA7WiA=s64","userId":"15268458970073686622"}},"outputId":"9afc62d2-81de-4acf-c77a-3b1eafca3c62"},"source":["len(ds['1']) # size of dataset with label 'person'"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["164688"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"BGXQoZfDA9q_"},"source":["# creating datasets for training\n","for k in range(4):\n","  output_dict = [x['caption'] for x in train_dataset['annotations'] if x['id'] in ds['1'][k*10000:(k+1)*10000]]\n","  with open('CTRL/dataset10k_ +' + str(k+1) + '.txt','w') as f:\n","    for line in output_dict:\n","      f.write(line)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TvRCa08BJLyM"},"source":["# creating dataset with prompts\n","output_dict = [x['caption'] for x in train_dataset['annotations'] if x['id'] in ds['1'][-1000:]]\n","with open('CTRL/prompts.txt','w') as f:\n","  for line in output_dict:\n","    line = line.split(' ')\n","    f.write('Person '+ line[0] + ' ' + line[1]+'\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cJ7m49tWOlMj"},"source":["# creating sample dataset for evaluation\n","output_dict = [x['caption'] for x in train_dataset['annotations'] if x['id'] in ds['1'][40000:41000]]\n","with open('CTRL/sample_dataset.txt','w') as f:\n","  for line in output_dict:\n","    f.write(line+'\\n')"],"execution_count":null,"outputs":[]}]}